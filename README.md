# Dagster, dbt, and ClickHouse Example

This repository demonstrates how to integrate **Dagster**, **dbt**, and **ClickHouse** to create a data pipeline for extracting, transforming, and loading (ETL) data efficiently.

## ğŸš€ Overview

- **Dagster**: Orchestrates the data pipeline, schedules jobs, and provides monitoring.
- **dbt (Data Build Tool)**: Handles SQL-based transformations, making data modeling easier.
- **ClickHouse**: A fast columnar database optimized for analytical workloads.

This project uses **Docker Compose** to spin up a local environment with all necessary components.

---

## ğŸ“‚ Project Structure
```bash
dagster-dbt-clickhouse-example/
â”‚â”€â”€ dags/                     # Dagster pipeline definitions
â”‚â”€â”€ dbt_project/               # dbt models and transformations
â”‚â”€â”€ clickhouse/                # ClickHouse setup
â”‚â”€â”€ docker-compose.yaml        # Docker Compose configuration
â”‚â”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Documentation
```
---

## ğŸ› ï¸ Setup and Installation

### 1ï¸âƒ£ Prerequisites

Ensure you have the following installed:

- **Docker & Docker Compose**: [Get Docker](https://docs.docker.com/get-docker/)
- **Git**: [Install Git](https://git-scm.com/)

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/dao-trung-hieu/dagster-dbt-clickhouse-example.git
cd dagster-dbt-clickhouse-example
```

### 3ï¸âƒ£ Start the Services

```bash
sudo docker compose up --build
```
This will spin up:

	â€¢	Dagster
	â€¢	dbt
	â€¢	ClickHouse

4ï¸âƒ£ Access the Dagster UI

Once the services are running, open your browser and go to:

	â€¢	Dagster UI: http://localhost:3000

